# ============================================================================
# LLM Service Environment Configuration
# Copy this file to .env and customize for your environment
# ============================================================================

# ============================================================================
# Compute Device Configuration
# ============================================================================
# COMPUTE_DEVICE options: "cuda", "cpu", "mps" (Apple Silicon)
# - cuda: Use NVIDIA GPU
# - cpu: Use CPU only
# - mps: Use Apple Silicon GPU (Metal Performance Shaders)
COMPUTE_DEVICE=cuda

# ============================================================================
# GPU Configuration (CUDA only)
# ============================================================================
GPU_DEVICE_ID=0
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=0
CUDA_MEMORY_FRACTION=0.95

# ============================================================================
# Model Configuration
# ============================================================================
# LLM model name (e.g., llama3.2:1b, llama3:8b, mistral:7b)
LLM_MODEL=llama3.2:1b

# Model storage path (inside container)
MODEL_PATH=/app/models

# Local path for model storage (bind mount)
MODELS_PATH=./models

# Local path for Ollama data storage (bind mount)
OLLAMA_DATA_PATH=./ollama-data

# ============================================================================
# Ollama Configuration
# ============================================================================
# Ollama API base URL
OLLAMA_BASE_URL=http://ollama:11434

# How long to keep model loaded (e.g., 5m, 1h, -1 for always)
OLLAMA_KEEP_ALIVE=5m

# Ollama request timeout (seconds)
OLLAMA_TIMEOUT=600.0

# ============================================================================
# Server Configuration
# ============================================================================
# WebSocket server host and port
LLM_HOST=0.0.0.0
LLM_PORT=8000

# Monitoring/metrics port
LLM_MONITORING_HOST=0.0.0.0
LLM_MONITORING_PORT=9092

# Maximum concurrent WebSocket connections
LLM_MAX_CONNECTIONS=50

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Local path for log storage (bind mount)
LOG_PATH=/app/logs
LOGS_PATH=./logs

# ============================================================================
# Generation Configuration
# ============================================================================
# Default generation parameters (can be overridden per-session)
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2048
DEFAULT_CONTEXT_WINDOW=8192
DEFAULT_TOP_P=0.9
DEFAULT_TOP_K=40

# ============================================================================
# Session Configuration
# ============================================================================
# Session timeout (seconds)
SESSION_TIMEOUT=3600

# Maximum conversation history length (messages)
MAX_HISTORY_LENGTH=50

# ============================================================================
# Performance Configuration
# ============================================================================
# Number of CPU threads (12 for CPU, 8 for Apple Silicon)
NUM_THREADS=12

# Number of worker processes
NUM_WORKERS=6

# CPU-specific threading (CPU mode only)
# OpenMP threads for parallel processing
OMP_NUM_THREADS=12

# Intel MKL threads (if using Intel MKL)
MKL_NUM_THREADS=12

# OpenBLAS threads (if using OpenBLAS)
OPENBLAS_NUM_THREADS=12

# Apple Silicon-specific (MPS mode only)
# Enable MPS fallback to CPU for unsupported operations
PYTORCH_ENABLE_MPS_FALLBACK=1

# ============================================================================
# Resource Limits
# ============================================================================
# Memory limit for container (e.g., 32g, 16g, 8g)
# Recommended: 32g for GPU, 16g for CPU/Apple Silicon
MEM_LIMIT=32g

# CPU limit (CPU mode only, e.g., 8.0 for 8 cores)
CPU_LIMIT=8.0

# CPU reservation (minimum guaranteed, e.g., 4.0 for 4 cores)
CPU_RESERVATION=4.0

# Shared memory size for container (e.g., 2g, 1g)
SHM_SIZE=2g

# ============================================================================
# Network Configuration
# ============================================================================
# Docker network subnet for inter-service communication
NETWORK_SUBNET=172.20.0.0/16
NETWORK_GATEWAY=172.20.0.1

# ============================================================================
# Production Settings (Optional)
# ============================================================================
# Enable TLS/SSL (requires certificate setup)
# ENABLE_TLS=false
# TLS_CERT_PATH=/app/ssl/cert.pem
# TLS_KEY_PATH=/app/ssl/key.pem

# Enable authentication (requires auth token setup)
# ENABLE_AUTH=false
# AUTH_TOKEN_SECRET=your-secret-key-here

# Enable rate limiting
# RATE_LIMIT_ENABLED=false
# RATE_LIMIT_MAX_REQUESTS=100
# RATE_LIMIT_WINDOW_SECONDS=60
