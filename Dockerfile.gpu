# ============================================================================
# FastTalk LLM Service - GPU-Optimized Dockerfile
# Multi-stage build for production deployment
# ============================================================================

FROM fasttalk/base:cuda12.1-py310-torch260 AS builder

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive

# Create virtual environment that can see system site-packages (shared torch layer)
RUN python -m venv /opt/venv --system-site-packages

# Activate venv
ENV PATH="/opt/venv/bin:$PATH"

# Upgrade pip
RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# Copy requirements
COPY requirements.txt /tmp/requirements.txt

# Install Python dependencies (torch already satisfied from base layer)
RUN pip install --no-cache-dir -r /tmp/requirements.txt

FROM fasttalk/base:cuda12.1-py310-torch260

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv

# Activate venv
ENV PATH="/opt/venv/bin:$PATH"

# Create non-root user
RUN useradd -m -u 1000 -s /bin/bash appuser && \
    mkdir -p /app/logs /app/models && \
    chown -R appuser:appuser /app

# Set working directory
WORKDIR /app

# Copy application code
COPY --chown=appuser:appuser app/ /app/app/
COPY --chown=appuser:appuser main.py /app/
COPY --chown=appuser:appuser entrypoint.sh /app/

# Make entrypoint executable
RUN chmod +x /app/entrypoint.sh

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    LLM_PORT=8000 \
    LLM_MONITORING_PORT=9092

# Expose ports
EXPOSE 8000 9092

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=90s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Switch to non-root user
USER appuser

# Entry point
ENTRYPOINT ["/app/entrypoint.sh"]
